# 5강. 훈련 노하우를 배웁니다

## 05-1. 검증 세트를 나누고 전처리 과정을 배웁니다
: 5강에서는 4강에서 다루었던 훈련 세트와 테스트 세트 중 '테스트 세트'의 사용 방법에 대해 조금 더 깊이 알아보자. 목표는 **어느 데이터 세트에만 치우친 모델을 만들지 않는 것**이다 

### 테스트 세트로 모델을 튜닝합니다
-> gogo colab!

### 테스트 세트로 모델을 튜닝하면 실전에서 좋은 성능을 기대하기 어렵습니다
: 테스트 세트는 실전에 투입된 모델의 성능을 측정하기 위해 사용한다. 그런데 테스트 세트 모델로 튜닝할 경우, '테스트 세트에 대해서만 좋은 성능을 보여주는 모델'이 만들어진다 즉 실전에서 같은 성능을 기대하기 어렵다. 이런 현상을 '테스트 세트의 정보가 모델에 새어 나갔다'라고 말한다.    
정리하면 테스트 세트로 모델을 튜닝하면 테스트 세트의 정보가 모델에 새어 나가므로 모델의 일반화 성능이 왜곡된다

### 검증 세트를 준비합니다
: 그럼 어떻게 해야 할까? 모델을 튜닝할 때 테스트 세트를 사용하지 않으면 된다. 하지만 모델을 튜닝하려면 성능 점수가 필요하다. 그러면 어떻게 해야 할까? 테스트 세트는 모델 튜닝을 모두 마치고 실전에 투입하기 전에 딱 한 번만 사용하는 것이 좋다 즉 모델 튜닝을 위한 세트는 따로 준비해야 한다. 모델을 튜닝하는 용도의 세트는 검증 세트라고 하며 훈련 세트를 조금 떼어 만든다. 예로 훈련 세트:검증 세트:테스트 세트 = 6:2:2 로 나누어 사용한다
-> gogo colab!

### 데이터 전처리와 특성의 스케일을 알아봅니다
: 사이킷런과 같은 머신러닝 패키지에 준비되어 있는 데이터는 대부분 실습을 위한 것이므로 잘 가공되어 있으나 실전에서 수집된 데이터는 그렇지 않다. 누락된 값이 있을 수도 있고 데이터의 형태가 균일하지 않을 수도 있다. 이런 데이터들을 그대로 사용하면 제대로 된 결과를 얻을 수 없으므로, 이런 경우 데이터를 적절히 가공하는 '데이터 전처리'과정이 필요하다. 이번에는 데이터 전처리에 대해 알아보자

- 특성의 스케일은 알고리즘에 영향을 줍니다. 
: 아쉽게도 이 책에서는 제대로 가공되지 않은 데이터를 다루지 않는다. 다만 잘 정리된 데이터도 전처리를 해야하는 경우가 있는데, 이는 특성의 스케일이 다른 경우이다. 특성의 스케일이란 어떤 특성이 가지고 있는 값의 범위를 말한다. 예를 들어 사과의 특성의 경우 당도는 1~10까지의 범위를 가지는 반면 무게는 500~1000을 가지는 경우이다 이 경우 '두 특성의 스케일 차이가 크다'라고 말한다 어떤 알고리즘들은 스케일에 민감하여 모델의 성능에 영향을 주는데, 이 책에서 소개하는 신경망 알고리즘들은 모두 경사 하강법을 사용한다. 경사 하강법은 스케일에 민감한 알고리즘이므로 특성의 스케일을 맞추는 등의 전처리를 해야 한다. 이때 특성의 스케일을 전처리 하는 것을 '스케일을 조정한다'라고 표현한다. 그러면 특성의 스케일을 조정하면 어떤 이점이 있을까? 다음의 실습을 통해 천천히 알아보자

### 스케일을 조정하지 않고 모델을 훈련해볼까요?
: 지금부터는 특성의 스케일이 서로 다른 데이터를 이용하여 모델을 훈련하면 가중치가 어떻게 변하는지 살펴보자.
-> gogo colab!

### 스케일을 조정해 모델을 훈련합니다
: 스케일을 조정하는 방법은 많지만 신경망에서 자주 사용하는 스케일 조정 방법 중 하나는 표준화이다. 표준화는 특성 값에서 평균을 빼고 표준 편자로 나누면 된다. 표준화를 하면 평균이 0이고 분산이 1인 특성이 만들어진다. 표준화 공식은 다음과 같다.  
** z = (x - μ) / s**
사이킷런에는 표준화를 위한 StandardScaler 클래스가 준비되어 있지만 여기서는 학습을 위해 직접 표준화를 구현해보자

-> gogo colab!


## 05-2. 과대적합과 과소적합을 알아봅니다
: 여기서는 훈련 세트와 검증 세트에 대한 모델의 성능에 대해 조금 더 깊이 고찰해 보도록 하자. 훈련 세트와 검증 세트는 모델의 과대 적합, 과소 적합이라는 문제와 깊은 연관이 있다. 

### 학습 곡선을 통해 과대적합과 과소 적합을 알아봅니다.
: 과대 적합이란 모델이 훈련 세트에서는 좋은 성능을 내지만 검증 세트에서는 낮은 성능을 내는 경우를 말한다. 예로, 훈련 세트의 정확도가 99%이고 검증 세트의 정확도가 80% 수준이라면 과대 적합을 의심할 수 있다. 반면에 과소 적합은 훈련 세트와 검증 세트의 성능에는 차이가 크지 않지만 모두 낮은 성능을 내는 경우를 말한다

- 훈련 세트의 크기와 과대 적합, 과소 적합 분석하기. 
: 훈련 세트의 크기에 따른 정확도의 변화 모습을 그래프로 표현한 학습 곡선을 통해 과대적합과 과소적합이 어떻게 나타나는지 확인할 수 있다.   
1. 훈련 세트와 검증 세트에서 측정한 성능의 간격이 클 경우 과대적합이며 이 모델을 '분산이 크다'라고도 말한다. 과대 적합이 일어나는 주요 원인 중 하나는 훈련 세트에 충분히 다양한 패턴의 샘플이 포함되지 않은 경우이다. 이 경우 더 많은 훈련 샘픔을 모아 검증 세트의 성능을 향상시킬 수 있다. 만약 현실적인 문제로 훈련 샘플을 더 많이 모을 수 없을 경우, 모델이 훈련 세트에 집착하지 않도록 가중치를 제한할 수 있다. 이를 '모델의 복잡도를 낮춘다'라고 말한다.
2. 훈련 세트와 검증 세트에서 측정한 성능의 간격은 점점 가까워지나 성능 자체가 낮은 경우 과소적합에 해당한다. 이 모델을 '편향이 크다'라고도 말한다. 과소 적합은 모델이 충분히 복잡하지 않아 훈련 데이터에 있는 패턴을 모두 잡아내지 못하는 현상이다. 해결 방법은, 복잡도가 더 높은 모델을 사용하거나 가중치의 규제를 완화하는 것이다.

- 에포크 손실 함수의 그래프로 과대적합과 과소적합 분석하기
: 4장에서 살펴본 에포크에 대한 손실 함수의 그래프를 사용하여 과대적합과 과소적합을 분석하기도 한다. 그래서 에포크에 대한 손실 함수의 그래프를 학습 곡선이라고 부르기도 한다. 에포크와 손실 함수에 대한 그래프와 에포크와 정확도에 대한 그래프를 통해 과대적합과 과소적합을 분석해보자
1. 검증세트의 손실과 훈련 세트의 손실을 표현했을때, 훈련 세트의 손실은 에포크가 진행될 수록 감소하지만 검증 세트의 손실은 에포크 횟수가 최적점을 지나면 오히려 상승한다.  최적점 이후에도 계속해서 훈련 세트로 모델을 학습시키면 모델이 훈련 세트의 샘플에 더 밀착하여 학습하기 때문이다. 즉 모델이 과대적합 되기 시작한다.
2. 최적점 이전에는 훈련 세트와 검증 세트의 손실이 비슷한 간격을 유지하면서 함께 줄어드는데, 이 영역에서 학습을 중지하면 과소 적합된 모델이 만들어진다

- 모델 복잡도와 손실 함수의 그래프로 과대적합과 과소적합 분석하기
: 가로축에 에포크 대신 모델 복잡도를 넣어 표현하기도 한다. 모델 복잡도란 모델이 가진 학습 가능한 가중치의 개수로, 이 개수가 많아질수록  복잡도가 높은 모델이 만들어진다   
모델이 복잡하다고 무조건 좋은 것은 아니다. 예를 들어 모델이 훈련 세트에만 잘 맞는 형태로 만들어지면 훈련 세트에서만 좋은 성능을 내기 때문이다. 과대적합이 이에 해당한다.

### 적절한 편향-분산 트레이오프를 선택합니다
: 과소적합된 모델(편향)과 과대적합된 모델(분산)사이의 관계를 편향-분산 트레이드오프라고 한다. 트레이드 오프란 '하나를 얻기 위해서는 다른 하나를 희생해야 함'라는 의미로 사용된 것이다. 즉 편향-분산 트레이드오프란 편향을 줄이면(훈련 세트의 성능을 높이면) 분산이 커지고(검증 세트와 성능 차이가 커지고) 반대의 경우 분산을 줄이면 편향이 커지는 것을 말한다. 따라서 우리는 분산, 편향이 너무 커지지 않도록 중간 지점을 선택해야 하는데 이러한 행위를 '적절한 편향-분산 트레이드오프를 선택했다'라고 한다. 경사 하강법의 에포크 횟수에 대한 모델의 손실을 그래프로 그려 '적절한 편향-분산 트레이드오프'를 선택해보자

->gogo colab!



## 05-3. 규제 방법을 배우고 단일층 신경망에 적용합니다
: 05-2에서 과대적합을 설명하면서 과대적합을 해결하는 대표적인 방법 중 하나로 가중치 규제를 소개했다. 가중치 규제란 가중치의 값이 커지지 않도록 제한하는 기법으로 가중치를 규제하면 모델의 알반화 성능이 올라가게 된다
- 하나의 샘플 데이터에 대해 서로 다른 두 모델이 점을 어느정도 잘 표현하고 있다고 했을 때 둘 중 경사가 더 완만한 그래프가 성능이 좋다고 평가한다
- 샘플 데이터를 정확이 관통하는 모델일 경우(7개중 6개는 관통하나 1개는 빗나감) 좋은 성능을 가진 모델이라고 평가하지 않는다. 모델이 몇 개의 데이터에 집착하면 새로운 데이터에 적응을 하지 못하기 때문이다. 이것을 '모델이 일반화되지 않았다'고 말한다
: 두 번째 경우에서 규제를 사용하여 가중치를 제한하면 모델이 몇개의 데이터에 집착하지 않게 되므로 일반화 성능을 높일 수 있다. 대표적인 규제 기법인 L1,L2 규제를 살펴보자

### L1규제를 알아봅니다
: 손실 함수에 가중치의 절대값인 L1 노름을 추가하는 것으로, '가중치의 절댓값을 손실 함수에 더한 것'이라고 이해해도 된다.  
**L = 손실함수 + a * (L1규제) ( a는 규제의 양을 조절하는 파라미터)**.   
a의 값이 크면 전체 손실함수의 값이 커지지 않도록 w(벡터)값의 합이 작아져야 함 -> 규제가 강해짐. 
a의 값이 작으면 w의 합이 커져도 손실 함수의 값이 큰 폭으로 커지지 않음 -> 규제가 약해짐. 
다음으로 경사 하강법으로 가중치를 업데이트하기 위하여 L1규제를 적용한 로지스틱 손실 함수를 미분해보자

### L1 규제의 미분
: |w|는 미분할 경우 부호만 남게 되므로  w값을 미분한 결과인 w의 부호라는 의미로 sign(w)라고 표현한다.  이 경우 L1규제를 적용한 손실함수의 도함수는 다음과 같다   
**(∂/∂w)L = -(y-a) * x + a * sign(w)**

- 회귀 모델에 L1규제를 추가한 것을 라쏘 모델이라고 한다
: 사이킷런에서 sklearn.linear_model.Lasso 클래스에서 라쏘 모델을 제공한다. 
SGDClassifier클래스에서는 penalty 매개변수 값을 l1으로 지정하는 방법으로 L1규제를 적용할 수 있다

: 미분 결과에서 알 수 있듯이 L1규제는 규제 하이퍼파라미터 a에 많이 의존한다. 즉 가중치의 크기에 따라 규제의 양이 변하지 않으므로 규제 효과가 좋다고 할 수 없다. 다음으로 규제 효과가 좋아 널리 사용되는 L2규제에 대해 알아보자

### L2 규제를 알아봅니다
: L2 규제는 손실 하수에 가중치에 대한 L2 노름의 제곱을 더합니다

### L2 규제의 미분
: 로지스틱 손실 함수의 미분은 이전과 동일하게 진행하며, L2 규제를 미분하면 간단히 가중치 벡터 w만 남는다. 
**(∂/∂w)L = -(y-a) * x + a * w**
L2 규제는 그레디언트 계산에 가중치의 값 자체가 포함되므로 가중치의 부호만 사용하는 L1 규제 보다 조금 더 효과적이다. 또한 L2 규제는 가중치를 완전히 0으로 만들지 않는다. 가중치가 0일 경우 특성을 제외하는 효과는 있으나 모델의 복잡도가 떨어진다. 이러한 이유로 L2 규제를 널리 사용한다

- 회귀 모델에 L2 규제를 적용한 것을 릿지 모델이라고 합니다
: 사이킷런에서 sklearn.linear_model.Ridge 클래스에서 릿지 모델을 제공한다.   SGDClassifier클래스에서는 penalty 매개변수 값을 l2으로 지정하는 방법으로 L2규제를 적용할 수 있다

### L1규제와 L2규제 정리
: 다음은 L1, L2 규제를 경사하강법에 추가하는 방법을 정리한것이다
1. L1 규제 : 그레디언트에서 alpha에 가중치의 부호를 곱하여 그레디언트에 더함. 
**w_grad += alpha * np.sign(w)**
2. L2규제 : 그레디언트에서 alpha에 가중치를 곱하여 그레디언트에 더함  
**w_grad += alpha * w**

### 로지스틱 회귀에 규제를 적용합니다
-> gogo colab!


## 05-4. 교차 검증을 알아보고 사이킷런으로 수행해 봅니다
