# 5강. 훈련 노하우를 배웁니다

## 05-1. 검증 세트를 나누고 전처리 과정을 배웁니다
: 5강에서는 4강에서 다루었던 훈련 세트와 테스트 세트 중 '테스트 세트'의 사용 방법에 대해 조금 더 깊이 알아보자. 목표는 **어느 데이터 세트에만 치우친 모델을 만들지 않는 것**이다 

### 테스트 세트로 모델을 튜닝합니다
-> gogo colab!

### 테스트 세트로 모델을 튜닝하면 실전에서 좋은 성능을 기대하기 어렵습니다
: 테스트 세트는 실전에 투입된 모델의 성능을 측정하기 위해 사용한다. 그런데 테스트 세트 모델로 튜닝할 경우, '테스트 세트에 대해서만 좋은 성능을 보여주는 모델'이 만들어진다 즉 실전에서 같은 성능을 기대하기 어렵다. 이런 현상을 '테스트 세트의 정보가 모델에 새어 나갔다'라고 말한다.    
정리하면 테스트 세트로 모델을 튜닝하면 테스트 세트의 정보가 모델에 새어 나가므로 모델의 일반화 성능이 왜곡된다

### 검증 세트를 준비합니다
: 그럼 어떻게 해야 할까? 모델을 튜닝할 때 테스트 세트를 사용하지 않으면 된다. 하지만 모델을 튜닝하려면 성능 점수가 필요하다. 그러면 어떻게 해야 할까? 테스트 세트는 모델 튜닝을 모두 마치고 실전에 투입하기 전에 딱 한 번만 사용하는 것이 좋다 즉 모델 튜닝을 위한 세트는 따로 준비해야 한다. 모델을 튜닝하는 용도의 세트는 검증 세트라고 하며 훈련 세트를 조금 떼어 만든다. 예로 훈련 세트:검증 세트:테스트 세트 = 6:2:2 로 나누어 사용한다
-> gogo colab!

### 데이터 전처리와 특성의 스케일을 알아봅니다
: 사이킷런과 같은 머신러닝 패키지에 준비되어 있는 데이터는 대부분 실습을 위한 것이므로 잘 가공되어 있으나 실전에서 수집된 데이터는 그렇지 않다. 누락된 값이 있을 수도 있고 데이터의 형태가 균일하지 않을 수도 있다. 이런 데이터들을 그대로 사용하면 제대로 된 결과를 얻을 수 없으므로, 이런 경우 데이터를 적절히 가공하는 '데이터 전처리'과정이 필요하다. 이번에는 데이터 전처리에 대해 알아보자

- 특성의 스케일은 알고리즘에 영향을 줍니다. 
: 아쉽게도 이 책에서는 제대로 가공되지 않은 데이터를 다루지 않는다. 다만 잘 정리된 데이터도 전처리를 해야하는 경우가 있는데, 이는 특성의 스케일이 다른 경우이다. 특성의 스케일이란 어떤 특성이 가지고 있는 값의 범위를 말한다. 예를 들어 사과의 특성의 경우 당도는 1~10까지의 범위를 가지는 반면 무게는 500~1000을 가지는 경우이다 이 경우 '두 특성의 스케일 차이가 크다'라고 말한다 어떤 알고리즘들은 스케일에 민감하여 모델의 성능에 영향을 주는데, 이 책에서 소개하는 신경망 알고리즘들은 모두 경사 하강법을 사용한다. 경사 하강법은 스케일에 민감한 알고리즘이므로 특성의 스케일을 맞추는 등의 전처리를 해야 한다. 이때 특성의 스케일을 전처리 하는 것을 '스케일을 조정한다'라고 표현한다. 그러면 특성의 스케일을 조정하면 어떤 이점이 있을까? 다음의 실습을 통해 천천히 알아보자

### 스케일을 조정하지 않고 모델을 훈련해볼까요?
: 지금부터는 특성의 스케일이 서로 다른 데이터를 이용하여 모델을 훈련하면 가중치가 어떻게 변하는지 살펴보자.
-> gogo colab!

### 스케일을 조정해 모델을 훈련합니다
: 스케일을 조정하는 방법은 많지만 신경망에서 자주 사용하는 스케일 조정 방법 중 하나는 표준화이다. 표준화는 특성 값에서 평균을 빼고 표준 편자로 나누면 된다. 표준화를 하면 평균이 0이고 분산이 1인 특성이 만들어진다. 표준화 공식은 다음과 같다.  
** z = (x - μ) / s**
사이킷런에는 표준화를 위한 StandardScaler 클래스가 준비되어 있지만 여기서는 학습을 위해 직접 표준화를 구현해보자

-> gogo colab!


## 05-2. 과대적합과 과소적합을 알아봅니다


## 05-3. 규제 방법을 배우고 단일층 신경망에 적용합니다


## 05-4. 교차 검증을 알아보고 사이킷런으로 수행해 봅니다
