# 4강. 분류하는 뉴런을 만듭니다

## 04-1. 초기 인공지능 알고리즘과 로지스틱 회귀를 알아봅니다.
: 로지스틱 회귀를 제대로 이해하기 위해, 로지스틱 회귀로 발전된 초창기 인공지능 알고리즘들을 순서대로 살펴보자

### 퍼셉트론(Perceptron)에 대해 알아봅니다
: 1957년 코넬 항공 연구소의 프랑크 로젠블라트는 이진 분류 문제에서 최적의 가중치를 학습하는 퍼셉트론 알고리즘을 발표하였다.
여기서 이진 분류(binary classification)란 임의의 샘플 데이터를 True/False로 구분하는 문제를 말하며,  과일이라는 샘플 데이터가 있을 때 사과인지, 아닌지를 판단하는 것이 이진분류에 해당한다

- 퍼셉트론의 전체 구조를 훑어봅니다.
: 퍼셉트론은 직선 방정식을 사용하므로, 3장에서 공부한 선형 회귀와 유사한 구조를 가지고 있다. 하지만 퍼셉트론은 마지막 단계에서 샘플을 이진 분류하기 위하여 계단 함수(step function)라는 것을 사용한다. 계단 함수를 통과한 값을 다시 가중치와 절편을 업데이트(학습)하는데 사용한다.  
뉴런은 입력 신호 w1x1, w2x2, b 를 받아 z를 만든다. 즉 다음 수식에 의해 z를 만드는 것이다. 지금부터 아래의 수식을 '선형 함수'라고 부르겠다. 
**w1x1 + w2x2 + b = z**  
계단 함수는 z가 0보다 크거나 같으면 1로, 0보다 작으면 -1로 분류한다. 이때 1을 양성 클래스(positive class), -1을 음성 클래스(negative class)라고 부르며 위 함수를 그래프로 그리면 계단 모양이 되는 것을 확인할 수 있다.  
쉽게 말해, 퍼셉트론은 선형함수를 통과한 값 z를 계단함수로 보내 0보다 큰지, 작은지 검사하여 1과 -1로 분류하는 아주 간단한 알고리즘이다. 퍼셉트론은 계단 함수의 결과를 사용하여 가중치와 절편을 업데이트한다.

- 지금부터 여러개의 특성을 사용하겠습니다.
: 3장에서 본 뉴런의 특성이 1개인 것에 비해 4장에서 배운 뉴런의 입력 신호 특성에는 2개가 있다.  
앞으로는 여러 특성을 사용하여 문제를 해결하는 경우가 많이 나오므로, 아래와 같이 특성이 n개인 선형 함수 표기법에 익숙해지도록 하자.  
**w1x1 + w2x2 + ... + wnxn + b = z(n번째 특성의 가중치와 입력)**    


### 아달린(Adaline)에 대해 알아봅니다
: 퍼셉트론이 등장한 이후 1960년에 스탠포드 대학의 버나드 위드로우와 테드 호프가 퍼셉트론을 개선한 적응형 선형 뉴런을 발표하였다. 적응현 선형 뉴런은 아달린이라고도 부른다. 아달린은 선형 함수의 결과를 학습에 사용하며, 계단 함수의 결과는 예측에만 활용한다.

### 로지스틱 회귀(logistic regression)에 대해 알아봅니다
: 로지스틱 회귀는 아달린에서 조금 더 발전한 형태를 취하고 있다.
1. 활성화 함수(activation function): 선형 함수를 통과시켜 얻은 z를 임계함수에 보내기 전에 변형시키는 함수
2. 임계 함수(threshold function):  로지스틱 회귀의 마지막 단계에서 사용하는 함수로, 예측을 수행한다.아달린이나 퍼셉트론의  계단 함수와 역할은 비슷하나 활성화 함수의 출력값을 사용한다는 점이 다르다.

- 활성화 함수는 비선형 함수를 사용합니다
: 만약 활성화 함수가 선형 함수일 경우, 활성화 함수(y = kx)와 w1x1 + w2x2 + ... + wnxn + b = z 두 식을 쌓을 경우, 덧셈과 곱셈의 결합법칙과 분배법칙에 의해 정리하면 다시 하나의 큰 선형 함수가 되어 임계 함수 앞에 뉴런을 여러개 쌓아도 결국 선형함수일 것이므로 별 의미가 없게 된다. 그래서 활성화 함수는 의무적으로 비선형 함수를 사용한다. 로지스틱 회귀에는 '시그모이드 함수'가 활성화 함수로 사용되었다


## 04-2. 시그모이드 함수로 확율을 만듭니다

### 시그모이드 함수의 역할을 알아봅니다
: 출력값 z는 활성화 함수를 통과하여 a가 되는데, 이때 로지스틱 회귀에서 사용하는 활성화 함수인 시그모이드 함수는 z를 0~1사이의 확률값으로 변환시켜주는 역할을 합니다. 즉, 시그모이드 함수를 통과한 값 a를 암 종양 판정에 사용하면 양성 샘플일 확율로 해석할 수 있습니다.

### 시그모이드 함수가 만들어지는 과정을 살펴봅니다
: 시그모이드 함수가 만들어지는 과정은 다음과 같습니다.  
 **오즈 비 > 로짓 함수 > 시그모이드 함수**.  
 
 - 오즈 비에 대해 알아볼까요?
 : 시그모이드 함수는 오즈 비(odds ratio)라는 통계를 기반으로 만들어집니다. 오즈 비는 성공 확률과 실패 확률의 비율을 나타내는 통계이며 다음과 같이 정의 합니다.  
 **OR = p/1-p(p = 성공 확률)**  
 오즈 비를 그래프로 그리면 p가 0~1까지 증가할 때 오즈 비의 값은 처음에는 천천히 증가하지만 1에 가까워지면 급격히 증가합니다.
 
 - 로짓 함수에 대해 알아볼까요?
 : 오즈 비에 로그 함수를 취하여 만든 함수를 로짓 함수(logit function)라고 합니다. 로짓 함수의 식은 다음과 같습니다.  
 **logit(p) = log(p/1-p)**. 
 로짓 함수는 p가 0.5일 때 0이 되고, p가 0,1일 때 각각 무한대로 음수와 양수가 되는 특징을 가집니다. 
 로짓함수의 세로축을 z, 가로 축을 p로 놓으면 확률이 0~1까지 변할 때, z가 매우 큰 음수에서 매우 큰 양수까지 변하는 것으로 생각할 수 있습니다. 이 식은 다음과 같이 쓸 수 있습니다
 **log(p/1-p) = z**. 
 
 - 로지스틱 함수에 대해 알아볼까요?
 : 위 식을 다시 z에 대하여 정리하면 다음의 식이 됩니다. z에 대해 정리하는 이유는 가로 축을 z로 놓기 위해서 입니다. 그리고 이 식을 로지스틱 함수라고 부릅니다. 
**p = 1 / 1+e^-z**. 
로지스틱 함수를 그래프로 그려보면 로짓 함수의 가로와 세로 축을 반대로 뒤집어 놓은 모양이 됩니다. 그리고 그래프는 S자 형태를 띄게 됩니다. 이 모양에서 착안하여 로지스틱 함수를 시그모이드 함수(sigmoid function)라고도 부릅니다.

### 로지스틱 회귀 중간 정리하기
: 로지스틱 회귀는 이진 분류가 목표이므로 -무한대~무한대 범위를 가지는 z의 값을 조절할 방법이 필요했습니다. 그래서 시그모이드 함수를 활성화 함수로 사용한 것이죠. 이는 시그모이드 함수를 통과하면 z를 확률처럼 해석할 수 있기 때문입니다. 그리고 시그모이드 함수의 확률인 a를 0,1로 구분하기 위하여 마지막에 임계함수를 사용했습니다. 그 결과 입력 데이터x 는 0 또는 1의 값으로 나누어졌습니다. 즉, 이진 분류가 되었습니다. 즉, 로지스틱 회귀가 이진분류를 하기 위한 알고리즘인 이유를 알았습니다.   
그런데 아직 우리는 가중치와 절편을 적절하게 업데이트 할 수 있는 방법을 배우지 않았습니다. 다음장에서는 로지스틱 회귀를 위한 손실함수인 로지스틱 손실 함수에 대해 알아보겠습니다.
